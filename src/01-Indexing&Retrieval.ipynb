{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cef0a52f-e420-4ca1-b3b4-98a737b5db74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tutorial: https://github.com/terrier-org/cikm2021tutorial/tree/main\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyterrier as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e378b8b3-9565-4a82-b671-b2ed72b6d708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "61ca0cc3-460f-4419-856f-bbf63ee11e56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dataset = pt.datasets.get_dataset(\"msmarco_document\")\n",
    "dataset = pt.datasets.get_dataset(\"vaswani\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e025d9a-3fc3-4d5b-a5cc-9b492029d7b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'docno': '1', 'text': 'compact memories have flexible capacities  a digital data storage\\nsystem with capacity up to bits and random and or sequential access\\nis described'}\n",
      "{'docno': '2', 'text': 'an electronic analogue computer for solving systems of linear equations\\nmathematical derivation of the operating principle and stability\\nconditions for a computer consisting of amplifiers'}\n",
      "{'docno': '3', 'text': 'electronic coordinate transformer  circuit details are given for\\nthe construction of an electronic calculating unit which enables\\nthe polar coordinates of a vector modulus and cosine or sine of the\\nargument to be derived from those of a rectangular system of axes'}\n",
      "{'docno': '4', 'text': 'the british computer society  report of a conference held in cambridge\\njune'}\n",
      "{'docno': '5', 'text': 'millimicrosecond digital computer logic  a system of fast pulse\\nlogic is described which combines the efficiency of transformer coupled\\nstages with digit delay tolerances approaching that of dc coupled\\nsystems  logical circuits for or and inverter and reclock are shown\\ntogether with a driver which permits a fan out factor of  transistor\\ncircuits are used through'}\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(dataset.get_corpus_iter()):\n",
    "    print (d)\n",
    "    if (i > 3):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bf7d1f9f-e95b-421d-965a-04ea96e19692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_path = \"./vaswani_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d8589357-a7a0-4039-963a-7f3ce103add4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexer = pt.TRECCollectionIndexer(index_path, blocks=True)\n",
    "indexref = indexer.index(dataset.get_corpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6f71c148-d8d6-4ce0-a1d2-75ab827790f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./vaswani_index/data.properties'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexref.toString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "39ab2e9e-85d3-4fda-b5b7-5acf7f490a45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 11429\n",
      "Number of terms: 7756\n",
      "Number of postings: 224573\n",
      "Number of fields: 0\n",
      "Number of tokens: 271581\n",
      "Field names: []\n",
      "Positions:   true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = pt.IndexFactory.of(indexref)\n",
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "33e27110-c8b9-44a0-bca7-cc8d8a224c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7750 geocyclotron\n",
      "7751 incur\n",
      "7752 climatolog\n",
      "7753 ephi\n",
      "7754 handlett\n",
      "7755 sansserif\n"
     ]
    }
   ],
   "source": [
    "lex = index.getLexicon()\n",
    "\n",
    "for termid in range(7750, 7756):\n",
    "    lee = lex.getLexiconEntry(termid)\n",
    "    print (termid, lee.getKey())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fb972e8a-8304-4bf8-b259-b1d79ac8e1ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[948, 950, 2863, 3164, 3462, 3496, 4898, 4953, 5071, 5538, 5667, 5815, 6711, 6829, 6862, 6942, 6991, 7436, 7870, 8557, 8959, 9236, 9778, 9974, 10159, 10857]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Posting list del término ´x´\n",
    "meta = index.getMetaIndex()\n",
    "inv  = index.getInvertedIndex()\n",
    "#\n",
    "le = lex.getLexiconEntry(\"run\")\n",
    "\n",
    "\n",
    "list_docs  = []\n",
    "list_freqs = []\n",
    "# the lexicon entry is also our pointer to access the inverted index posting list\n",
    "for posting in inv.getPostings(le):\n",
    "    docno = meta.getItem(\"docno\", posting.getId())\n",
    "    #print(\"(%s, %d), \" % (docno, posting.getFrequency()), end = '')\n",
    "    list_docs.append(int(docno))\n",
    "    list_freqs.append(int(posting.getFrequency()))\n",
    "#\n",
    "print (list_docs)\n",
    "print (list_freqs)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f1f0f230-fca1-4fa0-ae65-ea6ac647eb3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electron with frequency 2\n",
      "given with frequency 1\n",
      "measur with frequency 1\n",
      "densiti with frequency 1\n",
      "compon with frequency 1\n",
      "squar with frequency 1\n",
      "frequenc with frequency 1\n",
      "analys with frequency 1\n",
      "determin with frequency 1\n",
      "signal with frequency 1\n",
      "rate with frequency 1\n",
      "shift with frequency 1\n",
      "excess with frequency 1\n",
      "wave with frequency 2\n",
      "observ with frequency 1\n",
      "term with frequency 1\n",
      "ordinari with frequency 1\n",
      "valu with frequency 1\n",
      "satellit with frequency 2\n",
      "artifici with frequency 2\n",
      "ionospher with frequency 2\n",
      "radio with frequency 1\n",
      "distribut with frequency 1\n",
      "fade with frequency 4\n",
      "appar with frequency 1\n",
      "doppler with frequency 1\n",
      "differ with frequency 1\n",
      "upper with frequency 1\n",
      "forth with frequency 1\n",
      "yield with frequency 1\n",
      "content with frequency 1\n",
      "extraordinari with frequency 1\n",
      "outlin with frequency 1\n",
      "procedur with frequency 1\n",
      "vertic with frequency 1\n",
      "invers with frequency 1\n",
      "faradai with frequency 4\n",
      "exactli with frequency 1\n",
      "proport with frequency 1\n",
      "explan with frequency 1\n"
     ]
    }
   ],
   "source": [
    "# Términos en un doc\n",
    "di = index.getDirectIndex()\n",
    "doi = index.getDocumentIndex()\n",
    "lex = index.getLexicon()\n",
    "docid = 101 #docids are 0-based\n",
    "#NB: postings will be null if the document is empty\n",
    "for posting in di.getPostings(doi.getDocumentEntry(docid)):\n",
    "    termid = posting.getId()\n",
    "    lee = lex.getLexiconEntry(termid)\n",
    "    print(\"%s with frequency %d\" % (lee.getKey(),posting.getFrequency()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5b9ea9e1-ff60-4946-90e5-740c9b45228c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lexicon = index.getLexicon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f01e565b-f493-438c-a5f1-c7ea049d9294",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7756"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5b64d400-c263-43d2-b7ac-5ccaa9812ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<org.terrier.structures.Lexicon at 0x7ff9dcc51260 jclass=org/terrier/structures/Lexicon jself=<LocalRef obj=0x56070163a6a0 at 0x7ff9dcc8a7f0>>\n"
     ]
    }
   ],
   "source": [
    "print (lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "864ff300-b288-45ae-8f85-a015d9cfd181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<java.util.Map$Entry at 0x7ff9dc5e62f0 jclass=java/util/Map$Entry jself=<LocalRef obj=0x56070163a6f8 at 0x7ff9dcc62610>>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (lexicon.getIthLexiconEntry(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7372876-0b45-4930-bfca-581a194523c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffcc090-68a2-4893-8349-95df76813106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0526e85f-06aa-4eda-864f-fb537ef076fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8dd6b682-4cbb-4736-bcf2-6e8223d6e0e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Probar compresion\n",
    "# https://github.com/searchivarius/PyFastPFor/blob/master/python_bindings/examples.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c31aa7e5-3816-4693-a2da-908a69ab739e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyfastpfor\n",
      "  Downloading pyfastpfor-1.3.6.tar.gz (165 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.4/165.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pybind11>=2.0 (from pyfastpfor)\n",
      "  Using cached pybind11-2.10.4-py3-none-any.whl (222 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pyfastpfor) (1.24.3)\n",
      "Building wheels for collected packages: pyfastpfor\n",
      "  Building wheel for pyfastpfor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyfastpfor: filename=pyfastpfor-1.3.6-cp310-cp310-linux_x86_64.whl size=428464 sha256=cecfe0486d67e0eea3801b65123567aafdb8f7503db3ca97100a0feb55df464a\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/10/61/2a/0a26b0c266984d86decd330a4a4f96c3f2a453e5bdeb772c8c\n",
      "Successfully built pyfastpfor\n",
      "Installing collected packages: pybind11, pyfastpfor\n",
      "Successfully installed pybind11-2.10.4 pyfastpfor-1.3.6\n"
     ]
    }
   ],
   "source": [
    "!pip install pyfastpfor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4936da9e-e20b-44ec-ba52-514c24eb56a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BP32',\n",
       " 'copy',\n",
       " 'fastbinarypacking16',\n",
       " 'fastbinarypacking32',\n",
       " 'fastbinarypacking8',\n",
       " 'fastpfor128',\n",
       " 'fastpfor256',\n",
       " 'maskedvbyte',\n",
       " 'newpfor',\n",
       " 'optpfor',\n",
       " 'pfor',\n",
       " 'pfor2008',\n",
       " 'simdbinarypacking',\n",
       " 'simdfastpfor128',\n",
       " 'simdfastpfor256',\n",
       " 'simdgroupsimple',\n",
       " 'simdgroupsimple_ringbuf',\n",
       " 'simdnewpfor',\n",
       " 'simdoptpfor',\n",
       " 'simdpfor',\n",
       " 'simdsimplepfor',\n",
       " 'simple16',\n",
       " 'simple8b',\n",
       " 'simple8b_rle',\n",
       " 'simple9',\n",
       " 'simple9_rle',\n",
       " 'simplepfor',\n",
       " 'streamvbyte',\n",
       " 'varint',\n",
       " 'varintg8iu',\n",
       " 'varintgb',\n",
       " 'vbyte',\n",
       " 'vsencoding']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyfastpfor import *\n",
    "import numpy as np\n",
    "# Get the list of all codecs\n",
    "getCodecList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f2db97f4-6f94-4efb-8685-700ac13b164c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression ratio: 0.3524\n"
     ]
    }
   ],
   "source": [
    "arrSize = 128 * 28\n",
    "maxVal = 2048\n",
    "# 1. Example without data differencing\n",
    "\n",
    "# All arrays the library use must be contiguous-memory C-style numpy arrays\n",
    "inp = sorted(np.array(np.random.randint(0, maxVal, arrSize), dtype = np.uint32, order = 'C'))\n",
    "inpCompDecomp = np.zeros(arrSize, dtype = np.uint32, order = 'C')\n",
    "\n",
    "# To be on the safe side, let's reserve plenty of additional memory:\n",
    "# sometimes the size of compressed data is not smaller than the size \n",
    "# of the original one\n",
    "inpComp = np.zeros(arrSize + 1024, dtype = np.uint32, order = 'C')\n",
    "\n",
    "# Obtain a codec by name\n",
    "#codec = getCodec('simdbinarypacking')\n",
    "codec = getCodec('pfor')\n",
    "\n",
    "# Compress data\n",
    "compSize = codec.encodeArray(inp, arrSize, inpComp, len(inpComp))\n",
    " \n",
    "print('Compression ratio: %g' % (float(compSize)/arrSize))\n",
    "\n",
    "# Decompress data\n",
    "assert(arrSize == codec.decodeArray(inpComp, compSize, inpCompDecomp, arrSize))\n",
    "assert(np.all(inpCompDecomp == inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "251109d4-7ead-420d-8843-0dc873710403",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3584 1263\n"
     ]
    }
   ],
   "source": [
    "print (arrSize, compSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "98da0ec9-36e7-43a5-bc4a-9044eb1327f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3584\n"
     ]
    }
   ],
   "source": [
    "print (len(inpCompDecomp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "10b3c6ec-b4fd-41e2-bad5-5b175953fb56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_dgaps(docids):\n",
    "    refval = docids[0]\n",
    "    dgaps  = [refval]\n",
    "    for cur in range(1, len(docids)):\n",
    "        this_gap = docids[cur] - refval\n",
    "        #print (cur, refval, docids[cur], this_gap)\n",
    "        refval   = docids[cur]\n",
    "        dgaps.append(this_gap)\n",
    "    return dgaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c2dd7c38-fb8e-4322-90cd-8ea2776d987f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression ratio: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Comprimir list_docs y list_freqs (vienen de arriba)\n",
    "\n",
    "list_docs_size = len(list_docs)\n",
    "\n",
    "# To be on the safe side, let's reserve plenty of additional memory: sometimes\n",
    "# the size of compressed data is not smaller than the size of the original one\n",
    "list_docs_comp   = np.zeros(list_docs_size + 1024, dtype = np.uint32, order = 'C')\n",
    "list_docs_decomp = np.zeros(list_docs_size, dtype = np.uint32, order = 'C')\n",
    "\n",
    "# Obtain a codec by name\n",
    "codec = getCodec('simdbinarypacking')\n",
    "#codec = getCodec('pfor')\n",
    "codec = getCodec('vbyte')\n",
    "\n",
    "\n",
    "# Compress data\n",
    "list_docs_comp_size = codec.encodeArray(list_docs, list_docs_size, list_docs_comp, len(list_docs_decomp))\n",
    " \n",
    "print('Compression ratio: %g' % (float(list_docs_comp_size) / list_docs_size))\n",
    "\n",
    "# Decompress data\n",
    "assert(list_docs_size == codec.decodeArray(list_docs_comp, list_docs_comp_size, list_docs_decomp, list_docs_size))\n",
    "assert(np.all(list_docs_decomp == list_docs))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "390c066d-5e13-4d44-837c-12e1d89afe5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0\n"
     ]
    }
   ],
   "source": [
    "print (float(list_docs_comp_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c8d0bfa5-58c6-42bf-8e23-98a4b1ddeeaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute dgaps\n",
    "list_docs_dgaps = compute_dgaps(list_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "93f71120-dc2a-40fd-8130-965bf6e0cfcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression ratio: 0.423077\n"
     ]
    }
   ],
   "source": [
    "# Compress data\n",
    "list_docs_comp_size2 = codec.encodeArray(list_docs_dgaps, list_docs_size, list_docs_comp, len(list_docs_decomp))\n",
    " \n",
    "print('Compression ratio: %g' % (float(list_docs_comp_size2) / list_docs_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "41946c45-9300-415a-8ee2-be32dddb5029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_docs_1 = sorted(np.array(np.random.randint(1, 2, list_docs_size), dtype = np.uint32, order = 'C'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ee6f70ad-96cf-4a9e-a64a-f8a89113dcfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_docs_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8373c07b-5ac9-4437-b53a-f76f58b4904b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression ratio: 0.269231\n"
     ]
    }
   ],
   "source": [
    "list_docs_comp_size3 = codec.encodeArray(list_docs_1, list_docs_size, list_docs_comp, len(list_docs_decomp))\n",
    " \n",
    "print('Compression ratio: %g' % (float(list_docs_comp_size3) / list_docs_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f3d71212-2b22-4e4a-bc79-cca5500f3c60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0\n",
      "7.0\n",
      "26.0\n"
     ]
    }
   ],
   "source": [
    "print (float(list_docs_comp_size2))\n",
    "print (float(list_docs_comp_size3))\n",
    "print (float(list_docs_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c9c5305d-476d-48e6-b0e7-6309e8bb47f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pibiri\n",
    "# https://github.com/jermp/data_compression_course\n",
    "\n",
    "\n",
    "# Compression ratio: ratio of the size of the compressed data to the size of the original data. \n",
    "# The higher the compression ratio, the more space is saved by compression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c96bc7-8ec4-4b6b-8466-703674411e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33a3433-2134-4357-b21d-3aa1cee3aed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c547e59-eeb7-4584-8e31-4db954abac5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
