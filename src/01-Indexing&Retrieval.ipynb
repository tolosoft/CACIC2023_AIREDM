{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef0a52f-e420-4ca1-b3b4-98a737b5db74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tutorial: https://github.com/terrier-org/cikm2021tutorial/tree/main\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e378b8b3-9565-4a82-b671-b2ed72b6d708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ca0cc3-460f-4419-856f-bbf63ee11e56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importamos un dataset (corpus) desde el repo de pyTerrier: https://pyterrier.readthedocs.io/en/latest/datasets.html\n",
    "#\n",
    "dataset_name = \"vaswani\"\n",
    "dataset = pt.datasets.get_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f73989-927e-407f-abc4-170dd58f3e52",
   "metadata": {},
   "source": [
    "### Parte 1 - Explorar el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b5dde7-f802-401f-bc3c-f47d13c4727f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtenemos el archivo de documentos\n",
    "dataset.get_corpus()\n",
    "\n",
    "# Pasamos los documentos a un dataframe\n",
    "documents = dataset.get_corpus_iter()\n",
    "df = pd.DataFrame(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c97d1c1-8e81-4165-80f4-a32bb167bc5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85f8421-9655-442c-b796-ca0d53d55b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25340c5e-0668-4961-bffa-a140912f9b96",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parte 2 - Indexar el corpus con pyTerrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8589357-a7a0-4039-963a-7f3ce103add4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "index_path = \"./vaswani_index\"\n",
    "\n",
    "if os.path.exists(index_path):\n",
    "    index = pt.IndexFactory.of(index_path+\"/data.properties\")\n",
    "else:\n",
    "    indexer  = pt.TRECCollectionIndexer(index_path, blocks=True)\n",
    "    indexref = indexer.index(dataset.get_corpus())\n",
    "    index = pt.IndexFactory.of(indexref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ab2e9e-85d3-4fda-b5b7-5acf7f490a45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtenemos estadísticas del índice\n",
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0f566c-1515-4936-998c-7b3d962bfc9b",
   "metadata": {},
   "source": [
    "**Exploramos el diccionario (lexicon)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e27110-c8b9-44a0-bca7-cc8d8a224c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtenemos el diccionario\n",
    "lex = index.getLexicon()\n",
    "\n",
    "# Salida:\n",
    "# término -> id, Nt, TF, maxTF, @\n",
    "#\n",
    "# donde:\n",
    "#       Nt es el DF, número de docs donde aparece el término (sirve para calcular el IDF).\n",
    "#       TF es la suma de los Tfs de los Nt docs.\n",
    "#       maxTF es el número total de ocurrencias del término.\n",
    "#       Los números entre @{} son punteros para Terrier.\n",
    "\n",
    "for i, kv in enumerate(lex):\n",
    "    print(\"%s -> %s\" % (kv.getKey(), kv.getValue().toString()))\n",
    "    #print(kv.getFrequency())\n",
    "    if (i > 10): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd4ca87-191d-417a-b2b0-19dad682fe00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtener el término a partir de un id\n",
    "termid = 3257\n",
    "#\n",
    "lee  = lex.getLexiconEntry(termid)\n",
    "term = lee.getKey()\n",
    "print (termid, term)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3638d3d0-18bc-4eda-bba5-344977a788ec",
   "metadata": {},
   "source": [
    "**Exploramos posting lists y documentos en el índice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bcb7d0-bf8b-4864-8900-2029276651d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtner la posting list del término ´x´\n",
    "pointer = index.getLexicon()[term]\n",
    "for posting in index.getInvertedIndex().getPostings(pointer):\n",
    "    print(posting.toString() + \" doclen = %d\" % posting.getDocumentLength())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0f230-fca1-4fa0-ae65-ea6ac647eb3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Términos en un doc\n",
    "di  = index.getDirectIndex()\n",
    "doi = index.getDocumentIndex()\n",
    "lex = index.getLexicon()\n",
    "#\n",
    "docid = 9127\n",
    "#\n",
    "for posting in di.getPostings(doi.getDocumentEntry(docid)):\n",
    "    termid = posting.getId()\n",
    "    lee    = lex.getLexiconEntry(termid)\n",
    "    print(\"Término '%s', TF = %d\" % (lee.getKey(), posting.getFrequency()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753d14ae-68d3-4127-add5-bcaf870a5be0",
   "metadata": {},
   "source": [
    "### Parte 3 - Ejecutar un experimento de recuperación (y evaluación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9ea9e1-ff60-4946-90e5-740c9b45228c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtenemos los 'topics'\n",
    "topics = dataset.get_topics()\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7372876-0b45-4930-bfca-581a194523c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos los 'qrels'\n",
    "qrels = dataset.get_qrels()\n",
    "qrels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cef7f1-ab0c-4930-8d7d-bf3e699e47cf",
   "metadata": {},
   "source": [
    "**Definimos modelos de recuperación a usar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffcc090-68a2-4893-8349-95df76813106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Búsquedas (más modelos en: http://terrier.org/docs/current/javadoc/org/terrier/matching/models/package-summary.html)\n",
    "model_tf    = pt.BatchRetrieve(index, wmodel=\"Tf\")\n",
    "model_tfidf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
    "model_bm25  = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "model_dlm   = pt.BatchRetrieve(index, wmodel=\"DirichletLM\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff71a267-da50-4542-81e3-ae36ebed68cb",
   "metadata": {},
   "source": [
    "**Ejecutamos una búsqueda**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb0d2a7-4ee9-43d1-a663-899ac78172ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "# Primero con con bm25 como modelo de RI\n",
    "model_bm25.search(\"chemical document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120451c-080b-47c3-8e0d-91bdd401a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora con con con dlm como modelo de RI\n",
    "model_dlm.search(\"chemical document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c26277a-d6e9-450c-8617-008e76d65639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Varios queries (a partir de un DF)\n",
    "many_queries = pd.DataFrame([[\"q1\", \"chemical document\"], [\"q2\", \"first document\"]], columns=[\"qid\", \"query\"])\n",
    "model_bm25.transform(many_queries)\n",
    "model_bm25(many_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fcbeca-e993-4267-9f33-a597c317cb56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "many_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741899d9-9dc8-4ab7-9f57-f06be93a2de5",
   "metadata": {},
   "source": [
    "### Parte 4 - Experimentos completos de Recuperación y Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c96bc7-8ec4-4b6b-8466-703674411e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un \"Experiment\" se define a partir de los modelos que queremos evaluar y los datos a usar. \n",
    "# Más opciones: https://pyterrier.readthedocs.io/en/latest/experiments.html\n",
    "\n",
    "pt.Experiment(\n",
    "    [model_bm25, model_dlm],                           # Que estamos evaluando? (modelos)\n",
    "    dataset.get_topics(),                              # Qué queries usamos?\n",
    "    dataset.get_qrels(),                               # Qué juicios de relevancia?\n",
    "    eval_metrics=[ \"P_5\", \"recall_10\", \"map\", \"ndcg_cut_10\"]                    # Qué métricas vamos a usar?\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b20747-5dd8-47a6-a0cc-e3144b81440b",
   "metadata": {},
   "source": [
    "**Ejecutar un experimento comparando precisión en varios valores de k**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33a3433-2134-4357-b21d-3aa1cee3aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = pt.Experiment(\n",
    "    [model_tf, model_bm25, model_dlm],                 # Que estamos evaluando? (modelos)\n",
    "    dataset.get_topics(),                              # Qué queries usamos?\n",
    "    dataset.get_qrels(),                               # Qué juicios de relevancia?\n",
    "    # baseline = 0,\n",
    "    # perquery = True,\n",
    "    names=[\"TF\", \"BM25\", \"DLM\"],\n",
    "    eval_metrics=[\"P\"]                                 # Qué métricas vamos a usar?\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5623a059-8795-4d1f-88d4-c887238b8d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ebabc-1362-4c76-bc97-3b527585fff8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = rs.T\n",
    "df.columns = list(df.values[:1])\n",
    "df = df.drop(df[df.index == \"name\"].index)\n",
    "df.columns = [\"TF\", \"BM25\", \"DLM\"]\n",
    "df.rank = [5, 10, 15, 20, 30, 100, 200, 500, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6283de-22f8-4869-8fe4-95b451141e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f1cbdd-c156-4de0-835a-b0893bbe43db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_rank = [5, 30, 100, 500, 1000]\n",
    "\n",
    "sel_index = ['P@'+str(x) for x in sel_rank] \n",
    "#\n",
    "tf_performance   = df['TF'].loc[sel_index]\n",
    "bm25_performance = df['BM25'].loc[sel_index]\n",
    "dlm_performance  = df['DLM'].loc[sel_index]\n",
    "#\n",
    "plt.plot(sel_rank, tf_performance,   'o--', markersize=4, label=\"TF\")\n",
    "plt.plot(sel_rank, bm25_performance, 'x--', markersize=4, label=\"BM25\")\n",
    "plt.plot(sel_rank, dlm_performance,  '^--', markersize=4, label=\"DLM\")\n",
    "\n",
    "#\n",
    "plt.grid()\n",
    "plt.xlabel(\"Rank\")\n",
    "plt.ylabel(\"P\")\n",
    "#\n",
    "locs, labels = plt.xticks(sel_rank, rotation=90)\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db32bf6c-6c0a-4a0f-b89d-7a1364983b8a",
   "metadata": {},
   "source": [
    "### Tarea \n",
    "**1) Ejecutar todo el set de consultas y calcular las principales métricas para k=[1, 5, 10, 50, 100] (cuidado, para R use *recall_10*)**\n",
    "\n",
    "**2) Ejecute el experimento separando los resultados query por query (perquery = True) y determine si el modelo 'ganador' (puede probar R y P) en promedio es el mismo para todos consideranto k = 10 (tip: calcule en cuántas consultas *gana* cada modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25c5613-5ea4-48f2-8842-f4e184d47160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da0a45d-82e0-4b8d-a69b-79dde6b88f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
